{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dn Ds on our data\n",
    "\n",
    "Interpretting Dn/Ds is challenging. It is not robust on short time scales. That said we see an overaboundance of synonymous mutations and have been asked to correct for the number of NS and S mutations. So we do it, keeping in mind the caveots.\n",
    "\n",
    "_NB: check http://bioinformatics.cvr.ac.uk/blog/calculating-dnds-for-ngs-datasets/ for reference_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy \n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import tempfile\n",
    "import sys\n",
    "import subprocess\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio import SeqIO\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio import codonalign\n",
    "from ast import literal_eval\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadFASTA(fastafile):\n",
    "    \"\"\"Reads sequences from a FASTA file.\n",
    "\n",
    "    'fastafile' should specify the name of a FASTA file.\n",
    "\n",
    "    This function reads all sequences from the FASTA file.  It returns the\n",
    "        list 'headers_seqs'.  This list is composed of a seq_record objects.\n",
    "    \"\"\"\n",
    "    seqs =[]\n",
    "    header = None\n",
    "    for seq_record in SeqIO.parse(fastafile, \"fasta\"):\n",
    "        seq_record.seq.alphabet=IUPAC.unambiguous_dna\n",
    "        seqs.append(seq_record)\n",
    "\n",
    "    return seqs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= ReadFASTA(\"../data/reference/NY.OR.main.fa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PB2=test[1]\n",
    "c = codonalign.CodonSeq(str(PB2.seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CodonSeq('ATGGATGTCAATCCGACTCTACTGTTCTTAAAAGTTCCAGCGCAAAATGCCATA...TAA', CodonAlphabet(Standard))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(477.9999999999982, 1793.0000000000064)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cList=codonalign.codonseq._get_codon_list(c)\n",
    "codonalign.codonseq._count_site_NG86(cList[:-1],k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outine\n",
    "\n",
    "1) Read in meta data and filter to samples that qualified for iSNV identification\n",
    "\n",
    "2) Count the number of iSNV in each sample\n",
    "        - Count NS and S\n",
    "        - Count by segment\n",
    "        \n",
    "3) For each sample for each segment\n",
    "        - Get OR.\n",
    "        - Calculate NS and S\n",
    "    - Add to table of NS and S for each segment\n",
    "    \n",
    "4) Calculate Dn/Ds for each segment and total genome.\n",
    "\n",
    "### To think about\n",
    "What reading frames are we using - at this point just the cononical\n",
    "    NS and S was defined as NS in any OR.\n",
    "Should we only use 1 sample per illness? - Probabily but not done at this point.\n",
    "\n",
    "We assume each mutation is in a unique codon  - almost certainly true but easily checked.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Meta file\n",
    "\n",
    "This work is much easier for me to do in R so we'll use that here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"../data/processed/secondary/meta_for_ns.s_calc.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = meta.loc[meta.snv_qualified==True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/Users/jt/lauring_lab_repos/variant_pipeline/scripts/\")\n",
    "from fasta_functions import StripGapsToFirstSequence, Align\n",
    "def get_meta(SPECID,meta):\n",
    "    \"\"\"This function takes a SPECID and data frame with meta data and\n",
    "    returns a dictionary of the meta data for that sample.\"\"\"\n",
    "    ID = meta.loc[meta.SPECID==SPECID,\"Id\"].unique()[0]\n",
    "    ID = ID.split(\".\")[0]\n",
    "    RUN = meta.loc[meta.SPECID==SPECID,\"run\"].unique()[0]\n",
    "    season = meta.loc[meta.SPECID==SPECID,\"season\"].unique()[0]\n",
    "    ENROLLID = meta.loc[meta.SPECID==SPECID,\"ENROLLID\"].unique()[0]\n",
    "    HOUSE_ID = meta.loc[meta.SPECID==SPECID,\"HOUSE_ID\"].unique()[0]\n",
    "    if RUN==\"vic\":\n",
    "        RUN=\"victoria\"\n",
    "    if RUN==\"vic_2\":\n",
    "        RUN=\"victoria_2\"\n",
    "    return({\"Id\":ID,\"run\":RUN,\"season\":season,\"enrollid\":ENROLLID,\"house_id\":HOUSE_ID})\n",
    "\n",
    "def run_to_OR(run):\n",
    "    \n",
    "    \"\"\"This function takes in the name of sequencing run from this study and returns the relative path\n",
    "    to the fasta files with the OR for that sample.\"\"\"\n",
    "    conversion={\"perth\":\"../data/reference/perth.OR.fa\",\n",
    "               \"perth_2\": \"../data/reference/perth.OR.fa\",\n",
    "               \"cali09\":\"../data/reference/cali09.OR.fa\",\n",
    "               \"cali09_2\":\"../data/reference/cali09.OR.fa\",\n",
    "               \"victoria\":\"../data/reference/victoria.OR.fa\",\n",
    "               \"victoria_2\":\"../data/reference/victoria.OR.fa\",\n",
    "               \"HK_1\":\"../data/reference/NY.OR.fa\",\n",
    "               \"HK_2\":\"../data/reference/NY.OR.fa\",\n",
    "               \"HK_6\":\"../data/reference/NY.OR.fa\",\n",
    "               \"HK_7\":\"../data/reference/NY.OR.fa\",\n",
    "               \"HK_8\":\"../data/reference/NY.OR.fa\"}\n",
    "    return(conversion[run])\n",
    "\n",
    "def trim_to_coding(fasta,SPECID,meta):\n",
    "    \"\"\"This funciton trims a sample fasta sequence to the reading frame defined in a separate fasta file\n",
    "    First the funciton takes in the SPECID and looks up where the sample fasta file will be using the meta data\n",
    "    available in the meta argument. For each sequence in the reference the function looks for the same sequence name\n",
    "    in the sample fasta. It then alings this and trims the gaps so we are left with just the OR.\"\"\"\n",
    "    \n",
    "    samp_meta = get_meta(SPECID,meta)\n",
    "    \n",
    "    regions = run_to_OR(samp_meta[\"run\"])\n",
    "    \n",
    "    coding = ReadFASTA(regions)\n",
    "    # cycle through fasta \n",
    "    OR=[]\n",
    "    for gene in fasta:\n",
    "        seg_id=gene.id  \n",
    "        gene.description = \"this is the test sample\" + gene.description\n",
    "        for code in coding:\n",
    "            code_id = code.id\n",
    "            if seg_id in code_id:\n",
    "                #print('working with %s' %seg_id) #and seg_id==\"NR\":\n",
    "                code_gene=Align([code,gene],\"/Users/jt/muscle3.8.31/\")\n",
    "                code_gene_trimmed = StripGapsToFirstSequence(code_gene)\n",
    "                code_gene_trimmed.id=code_id\n",
    "                code_gene_trimmed.name=code_id\n",
    "                OR.append(code_gene_trimmed)\n",
    "        \n",
    "    return(OR)\n",
    "def get_seq(specid_list,meta_run):\n",
    "    \"\"\"This function takes a list of SPECIDs and data frame with meta data for the samples.  It only returns the consensus sequences.\n",
    "    For each SPECID we get the meta data in dictionary form,g et the consensus fasta file, \n",
    "    Trim the new sequences to the coding regions and return a dictionary of the results indexed by SPECID.\"\"\"\n",
    "    sequences={}\n",
    "    for specid in specid_list:\n",
    "        meta = get_meta(specid,meta_run)\n",
    "        fa = \"../data/processed/\"+meta[\"run\"]+\"/parsed_fa/\"+meta[\"Id\"]+\".removed.parsed.fasta\"\n",
    "        seq = ReadFASTA(fa)\n",
    "    \n",
    "        for seg in seq:\n",
    "            seg.name=specid\n",
    "        \n",
    "        seg_coding = trim_to_coding(seq,specid,meta_run)\n",
    "        specid_key = '%s_%s_%s_%s_consensus' % (specid,meta[\"enrollid\"],meta[\"house_id\"],meta[\"season\"])\n",
    "        sequences[specid_key] = seg_coding \n",
    "    return(sequences)\n",
    "\n",
    "def get_NS_s(specid_list,meta_run):\n",
    "    counter = {\"PB2\":[0,0],\"PB1\":[0,0],\"PB1-F2\":[0,0],\n",
    "               \"PA\":[0,0],\"PA-X\":[0,0],\"HA\":[0,0],\"NP\":[0,0],\n",
    "               \"NR\":[0,0],\"M1\":[0,0],\"M2\":[0,0],\"NS1\":[0,0],\"NS2\":[0,0]}\n",
    "    seqs = get_seq(specid_list,meta_run)\n",
    "    # cycle through the samples\n",
    "    \n",
    "    for sample in seqs:\n",
    "        print sample\n",
    "        sample_seq = seqs[sample]# a list of seqrecords\n",
    "        for sequence in sample_seq: # cycle through seqrecords\n",
    "            seq_name = sequence.name\n",
    "            assert len(str(sequence.seq)) % 3 == 0, \"Sequence length is not a triple number\"\n",
    "            codon_sequence = codonalign.CodonSeq(str(sequence.seq))\n",
    "            cList = codonalign.codonseq._get_codon_list(codon_sequence)\n",
    "            print seq_name\n",
    "            counts = codonalign.codonseq._count_site_NG86(cList[:-1],k=1) # remove the stop codon\n",
    "            for seg in counter:\n",
    "                if seg==seq_name:\n",
    "                        counter[seg][0] += counts[0]\n",
    "                        counter[seg][1] += counts[1]\n",
    "    return(counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MH8393_51162_5275_2014-2015_consensus\n",
      "PB2\n",
      "PB1\n",
      "PB1-F2\n",
      "PA\n",
      "PA-X\n",
      "HA\n",
      "NP\n",
      "NR\n",
      "M1\n",
      "M2\n",
      "NS1\n",
      "NS2\n",
      "MH7884_50538_5126_2014-2015_consensus\n",
      "PB2\n",
      "PB1\n",
      "PB1-F2\n",
      "PA\n",
      "PA-X\n",
      "HA\n",
      "NP\n",
      "NR\n",
      "M1\n",
      "M2\n",
      "NS1\n",
      "NS2\n",
      "HS1455_50677_5158_2014-2015_consensus\n",
      "PB2\n",
      "PB1\n",
      "PB1-F2\n",
      "PA\n",
      "PA-X\n",
      "HA\n",
      "NP\n",
      "NR\n",
      "M1\n",
      "M2\n",
      "NS1\n",
      "NS2\n",
      "MH5300_UM41553_4113_2013-2014_consensus\n",
      "PB2\n",
      "PB1\n",
      "PB1-F2\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'TAA'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-2bce2961efb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNs_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_NS_s\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSPECID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-158-77e7ed9ccba7>\u001b[0m in \u001b[0;36mget_NS_s\u001b[0;34m(specid_list, meta_run)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mcList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodonalign\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodonseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_codon_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodon_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mseq_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodonalign\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodonseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_site_NG86\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# remove the stop codon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mseq_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jt/miniconda3/envs/ipykernel_py2/lib/python2.7/site-packages/Bio/codonalign/codonseq.pyc\u001b[0m in \u001b[0;36m_count_site_NG86\u001b[0;34m(codon_lst, k, codon_table)\u001b[0m\n\u001b[1;32m    429\u001b[0m                     \u001b[0mneighbor_codon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transversion'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_codon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;31m# count synonymous and non-synonymous sites\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0maa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcodon_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcodon\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m         \u001b[0mthis_codon_N_site\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthis_codon_S_site\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mneighbor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbor_codon\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'transition'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'TAA'"
     ]
    }
   ],
   "source": [
    "Ns_s = get_NS_s(meta.SPECID,meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
