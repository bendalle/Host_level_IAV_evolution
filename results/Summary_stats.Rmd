---
title: "Summary statistics"
author: "JT McCrone"
date: "10/30/2017"
output: github_document
---
```{r,echo=F}

# Set up packages
require(knitr)
require(ggplot2)
require(magrittr)
require(tidyverse)
if(!("package:tidyverse" %in% search())){
  require(dplyr)
  require(tidyr)
  require(purrr)
  require(readr)
  require(rlang)
}
require(HIVEr)
require(extrafont)
require(wesanderson)
set.seed(42) # Set seed so randomization is reproducible

# Set up figures
opts_chunk$set(fig.align="center",warning=TRUE,tidy=T,cache = T,echo=F)
theme_set(new = theme_classic()+ theme(
axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
axis.line.y = element_line(colour ='black',size=0.5,linetype='solid'),
text=element_text(family="Arial",size = 18))) # to make nice plots
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
cbPalette<-wes_palette("Zissou")
# Get widely used functions
#source("../scripts/useful_functions.R")
require(doMC)
doMC::registerDoMC(cores=4)

####### Write to summary results file ######
write_to_summary<-function(line_pattern,value){
  file = readLines("./results.table.tsv")
  line_pattern_regex = paste0("^",line_pattern)
  line = grep(line_pattern_regex,file)
  file[line] = paste0(line_pattern,"\t",value)
  writeLines(file,"./results.table.tsv")
}
```

First we'll read in the all_meta file. Which now contains every sample we ever touched. We will filter it so that it contains 1 entry per person. This handels the cases in  2014-2015 where we have mulitple samples/ person. Although the multiple samples are important when we pick which sample to use in looking at transmission, here we just are looking at dates on onset so one sample/ person will do.

When there are 2 samples we pick the one we sequenced unless we sequenced both then we take the one that qualified for snv identification with the titer as a tie braker. If we didn't sequence either sample we pick the one to include randomly. 

I should note we are taking one sample per person per infecting strain. There are cases where one person was sick twice in a season with H1N1 and H3N2. Those each counted in the meta_one. The pcr_result is used to identify transmission pairs later.

### Cohort stats

How many H3N2 and H1N1 did we sequence

```{r}
meta<-read_csv("../data/reference/all_meta.sequence_success.csv")
# Read in the meta data
# Get the number of infections (individuals) that were infected by each strain and in 2014-2015

meta %>% subset(pcr_result=="A/H3N2") %>%
  .$ENROLLID  %>% unique() %>% length()->H3N2_cases


meta %>% subset(pcr_result=="A/H1N1") %>%
  .$ENROLLID  %>% unique() %>% length()->H1N1_cases

meta %>% subset(season=="2014-2015") %>%
  .$ENROLLID  %>% unique() %>% length()->cases_2014_15


write_to_summary("H3N2 cases:",H3N2_cases)
write_to_summary("H1N1 cases:",H1N1_cases)
write_to_summary("2014-2015 cases:",cases_2014_15)
```

### Table 1 stats

Take the meta and split by strain and season. 
```{r}
meta %>% group_by(season,pcr_result) %>% summarise(count = length(unique(ENROLLID))) ->IAV_positive_individuals


IAV_positive_individuals %>% spread(season,count,fill = 0)->IAV_positive_individuals.table

knitr::kable(IAV_positive_individuals.table)
```


### Transmission rules. 

These apply to all cases where 2 individuals are sick within the same household within a week of eachtoher (difference in date of onset <= 7 days).

In the event of multiple possible donors we assume the donor is the individual with symptom onset nearest to the recipeient.

The donor and recipeint are never allowed to have symptom onset on the same day unless they are the only cases in the house. In this case we will randomize the pair and estimate a bottleneck in both directions.

If there are two possible donors with the same date of onset then we throw out any possible pair to that recipient.

Also we require that pairs have an L1-norm below the 5% percentile of the non household pairs.

First we will just need one sample per person per pcr result. Date of onset is important for this analysis not date of sampling - that comes in later. 
```{r}
# Get just one sample per enrollid per pcr_result. When multiple samples were taken then we take the mose relavent ones.

meta_one<-read_csv("../data/processed/secondary/meta_one.sequence.success.csv")

meta %>% subset(snv_qualified==T)%>% nrow()->snv_qual_isolates
meta %>% subset(snv_qualified==T)%>% 
  .$ENROLLID %>% unique()%>%length()->snv_qual_individuals

write_to_summary("High quality isolates:",snv_qual_isolates)
write_to_summary("High quality individuals:",snv_qual_individuals)

```

Tranmission pairs are cases where 2 people are sick with the same strain from the same household with 7 days of eachother (inclusive)

```{r,all}
all_pairs.tp <- read_csv("../data/processed/secondary/transmission_pairs.csv")

valid_pairs<-subset(all_pairs.tp,valid==T)

all_pairs.tp %>% .$HOUSE_ID %>% unique() %>% length()->concurrent_houses #houses with multiple infections

write_to_summary("Putative transmission events:",nrow(valid_pairs))
write_to_summary("Households with concurrent infection:",concurrent_houses )
```

This yields `r nrow(all_pairs.tp)` possible pairs. And `r nrow(valid_pairs)` valid pairs




## Summary table of transmission events
```{r,summary_table}
sum.table<-function(data,r=F){
  data %>% group_by(season,pcr_result) %>% summarize(houses=length(unique(HOUSE_ID)),pairs=length(ENROLLID1))->sum.long # each row is a pair
  sum.long %>%select(-houses) %>%spread(pcr_result,pairs,fill=0) %>% ungroup()->pairs
  pairs$total<-pairs$`A/H1N1`+pairs$`A/H3N2`
  
  totals<-data.frame(season="total",H1N1=sum(pairs$`A/H1N1`),H3N2=sum(pairs$`A/H3N2`),total=sum(pairs$`A/H1N1`)+sum(pairs$`A/H3N2`))
  names(totals)<-c("season","A/H1N1","A/H3N2","total")
  pairs<-rbind(pairs,totals)
  #print(kable(pairs))
  if(r==T){
    return(pairs)
  }
}
all.sum<-sum.table(valid_pairs,r=T)
```

However, we did not sequence every sample and every sample we sequenced did not yeild usable SNV data. We handeled `r nrow(meta)` samples. We sequenced `r nrow(subset(meta,sequenced==T))` samples or `r round(nrow(subset(meta,sequenced==T))/nrow(meta),2)*100`% of the samples. `r nrow(subset(meta,sequenced==T & gc_ul>1e3))` samples (`r round(nrow(subset(meta,sequenced==T & gc_ul>1e3))/nrow(meta),2)*100`%) had titers > 1000 genomes/ul and were sequenced. 

We had samples from `r length(unique(meta_one$ENROLLID))` inidividuals. We sequenced samples from `r nrow(subset(meta_one,sequenced==T))` or `r round(nrow(subset(meta_one,sequenced==T))/nrow(meta_one),2)*100`% of the individuals. 


```{r}
sequenced_pairs<-subset(valid_pairs,sequenced1==sequenced2 & sequenced2==T) # both samples were sequenced.
```


So the best we could hope for would be `r nrow(sequenced_pairs)`

```{r}
sequenced.sum<-sum.table(sequenced_pairs,r=T)
```



```{r}
snv_hopefull_pairs<-subset(valid_pairs,sequenced1==sequenced2 & sequenced2==T & gc_ul1>1e3 & gc_ul2>1e3) # Both pairs sequenced and high enough titers to look for snv
```

When we further restrict our analysis and require both samples to be greater than 10^3^ then we have `r nrow(snv_hopefull_pairs)` possible pairs. The 71 I quoted earlier included sequenced early samples and all 2014-2015 samples we handeled. I have remade the meta data csv for this analysis.

```{r}
snv_hopeful.sum<-sum.table(snv_hopefull_pairs,r=T)
```

```{r}

snv_pairs<-subset(valid_pairs,snv_qualified1==T & snv_qualified2==T) # Both samples sequenced with titers>1e3 and passed sequencing (ave cov >1000 in both duplicates if applicable)
snv.sum<-sum.table(snv_pairs,r=T)

write_to_summary("High quality transmission pairs:",
                 snv.sum$total[snv.sum$season=="total"])
```

## L1-norm

```{r}
qual<-read_csv("../data/processed/secondary/qual.snv.csv",
               col_types = list(
                 ENROLLID= col_character(),
                 SPECID = col_character(),
                 LAURING_ID = col_character(),
                 Id = col_character()
               )) # read in quality variant calls from all 
stopifnot(min(qual$freq.var)>0.02)
```

Now we will make all possible pair comparisions within a season and strain. Note - becuause we are using the meta_one data frame we are not accounting for intrahost dynamics (in season 2014-2015). We have set up meta_one to give us the highest quality iSNV data.


```{r}

possible_pairs.dist<-read_csv("../data/processed/secondary/possible.pairs.dist.csv")

cutoffs<-as.data.frame(quantile(possible_pairs.dist$L1_norm[possible_pairs.dist$Household==F],probs = seq(0,1,0.05))) # get the percentiles for the community pairs
names(cutoffs)<-"L1_norm"
cutoffs$threshold<-seq(0,1,0.05)
cutoffs<-cutoffs %>% rowwise() %>%
  mutate(valid_pairs=nrow(possible_pairs.dist[(possible_pairs.dist$valid==T & possible_pairs.dist$L1_norm<L1_norm),]))


ggplot(cutoffs,aes(y=valid_pairs,x=threshold))+geom_point()#+scale_x_continuous(breaks=cutoffs$L1_norm,labels = cutoffs$threshold)+xlab("Quantile")
kable(cutoffs)

possible_pairs.dist<-mutate(possible_pairs.dist,quality_distance=L1_norm<cutoffs$L1_norm[cutoffs$threshold==0.05])

# Add distance cut off data to all_pairs.tp

all_pairs.tp<-merge(all_pairs.tp,subset(possible_pairs.dist,select=c(ENROLLID1,ENROLLID2,quality_distance)),all.x = T)
all_pairs.tp$quality_distance[all_pairs.tp$snv_qualified_pair==F]<-NA


figure3A_data<-subset(possible_pairs.dist,valid==T | Household==F)
figure3A_data<-figure3A_data %>%
  select(season,SPECID1,SPECID2,L1_norm,valid,Household)
l1norm.p_tp<-ggplot(figure3A_data,
                    aes(x=L1_norm,fill=as.factor((valid-1)*-1),y=..ncount..))+
geom_histogram(color='white',binwidth = 7.5,boundary=0,position = 'dodge')+
  scale_fill_manual(name="",labels=c("Household transmision","Community pairs"),values = cbPalette[c(1,4)])+
  xlab("L1 Norm")+ylab("Normalized Count")+
  theme(legend.position = c(0.5,0.5))+
  geom_segment(aes(x=15,xend =cutoffs$L1_norm[cutoffs$threshold==0.05],y=0,yend=1),
               linetype=2,color=cbPalette[5],size=0.3)
l1norm.p_tp

# What is the count in the highest bin?
l1norm.p_tp.b<-ggplot_build(l1norm.p_tp)
subset(l1norm.p_tp.b$data[[1]],group==1)->group1
subset(l1norm.p_tp.b$data[[1]],group==2)->group2
max(group2$count)
max(group1$count)
write_to_summary("Max household bar:",max(group1$count))
write_to_summary("Max community bar:",max(group2$count))


write.csv(figure3A_data,"./Figures/data/Figure3A.csv")
print(cutoffs$L1_norm[cutoffs$threshold==0.05]) # I moved it 15 because of the bin size 
```

## Overall Summary

```{r}
all.intra<-meta %>% get_double() # Get those samples that come from longitundal pairs

sequenced.intra<-subset(meta,sequenced==T) %>% get_double() # Get those samples that come from longitundal pairs

snv_hopefull.intra<-subset(meta,sequenced==T& gc_ul>1e3) %>% get_double() # Get those samples that come from longitundal pairs

snv.intra<-subset(meta,snv_qualified==T) %>% get_double() # Get those samples that come from longitundal pairs

total.sum<-data.frame(Class=c("Households","Isolates","Individuals","Transmission pairs","Households with potential pairs","Longitudinal sampling"),
                      "All Samples"=c(length(unique(meta$HOUSE_ID)),
                                      nrow(meta),
                                      length(unique(meta$ENROLLID)),
                                      all.sum$total[6],
                                      length(unique(valid_pairs$HOUSE_ID)),
                                      length(unique(all.intra$ENROLLID))),
                      "Sequenced samples"=c(nrow(unique(subset(meta,sequenced==T,select=c(HOUSE_ID)))),
                                            nrow(subset(meta,sequenced==T)),
                                            nrow(unique(subset(meta,sequenced==T,select=c(ENROLLID)))),
                                            sequenced.sum$total[6],
                                            length(unique(sequenced_pairs$HOUSE_ID)),
                                            length(unique(sequenced.intra$ENROLLID))),
                      "Titers1e3" =c(nrow(unique(subset(meta,sequenced==T & gc_ul>1e3,select=c(HOUSE_ID)))),
                                     nrow(subset(meta,sequenced==T & gc_ul>1e3)),
                                     nrow(unique(subset(meta,sequenced==T & gc_ul>1e3,select=c(ENROLLID)))),
                                     snv_hopeful.sum$total[6],
                                     length(unique(snv_hopefull_pairs$HOUSE_ID)),
                                     length(unique(snv_hopefull.intra$ENROLLID))),
                      "SNV sequenced" = c(nrow(unique(subset(meta,snv_qualified==T ,select=c(HOUSE_ID)))),
                                          nrow(subset(meta,snv_qualified==T)),
                                          nrow(unique(subset(meta,snv_qualified==T ,select=c(ENROLLID)))),
                                          paste0(snv.sum$total[6]," (",nrow(subset(all_pairs.tp,valid==T & snv_qualified_pair==T & quality_distance==T)),")"),
                                          length(unique(snv_pairs$HOUSE_ID)),
                                          length(unique(snv.intra$ENROLLID))))
kable(total.sum)
```

```{r}
by_house<- valid_pairs %>% group_by(HOUSE_ID,season,pcr_result) %>%
  summarize(Individuals =length(unique(c(ENROLLID1,ENROLLID2))) )
x<- by_house %>% group_by(Individuals,season) %>%
  summarize(households=length(Individuals))

x %>% spread(season,households)->by_house.table

kable(by_house.table)
```
## Looking at transmission

Here are the functions used for plotting. 
```{r}
one_for_each_plotting<-function(df){
  df$offset_x.1<-min(df$donset) #This puts the points at the onset 
  df$offset_x.2<-max(df$donset) # it used to be offset_x 
  df$offset_y.1<-min(df$offset_y[df$donset==min(df$donset)])  # This needs work
  df$offset_y.2<-max(df$offset_y[df$donset==max(df$donset)])
  return(df[1,])
}


make_transmission_plot<-function(x,type="all"){ # type should be all or valid or invalid.
  stopifnot(type %in% c('all','valid','invalid'))
  #x<-plyr::adply(x,1,longform_pairs) # Each row is a pair so for each pair split the row into 2 rows 
  x<-longform_pairs(x)
  x<-subset(x,select=c(HOUSE_ID,pair_id,ENROLLID,pcr_result,season,onset,gc_ul,sequenced,sequenced_pair,titer_pair,snv_qualified_pair,valid,quality_distance)) # just select these columns for each row
  x<-plyr::ddply(x,~HOUSE_ID,function(x){ # This will be useful for ording the plotting - at least that's the hope. For each house get the first onset date and set the donset as the distance of each case from that date.
    min_onset<-min(x$onset)
    mutate(x,min_onset=min_onset,donset=onset-min_onset)
  })
  
  
  x<-x[order(x$min_onset,x$HOUSE_ID,decreasing = T),] # I told you it would be useful - based on the first onset in each house.
  HOUSE_order<-unique(x$HOUSE_ID) # This is the order we want the houses to be in on the plot
  
  
  x<-plyr::ddply(x,~HOUSE_ID,function(z){
    z$y_Id=which(HOUSE_order==unique(z$HOUSE_ID))*2 # where does this house fall in the order
    return(z)})
  
  
  # I don't really use this any more but it is useful if you want to offset points with the same x value by shifting them on the x axis
  x<- plyr::ddply(x, ~onset+y_Id, function(x){ # this applys an offset for different individuals who are sick on the same day
      if(length(unique(x$ENROLLID))>1){ # if there are mulitple people here
      ENROLLIDs<-sort(unique(x$ENROLLID),decreasing=T)
      x<-mutate(x,sort_order=match(ENROLLID,ENROLLIDs)-1,offset_x=as.numeric(donset+sort_order/5))
      }
    else{
      x<-mutate(x,offset_x=as.numeric(donset))
    }
    return(x)
    })
  
   x<- plyr::ddply(x, ~onset+y_Id, function(x){ # this applys an offset for different individuals who are sick on the same day
      if(length(unique(x$ENROLLID))>1){ # if there are mulitple people here
      ENROLLIDs<-sort(unique(x$ENROLLID),decreasing=T)
      x<-mutate(x,sort_order=match(ENROLLID,ENROLLIDs)-1,offset_y=y_Id+((-1*length(ENROLLIDs)+4)*sort_order-1))
      }
    else{
      x<-mutate(x,offset_y=y_Id)
    }
    return(x)
    })
  
  
  # Curves and such
  
   # if the onset date is the same for both add a a curve and aline - this will be interpretted as 2 curves later

  x$line=T # start with all lines
  x$curve=F
  x<-plyr::ddply(x,~pair_id,function(x){
    if(length(unique(x$onset))==1){ # This pair is sick on the same day # and they are the only ones in the house
      x$curve=T 
      }
    return(x)})

  # If there is point between the two in the pair add a curve and no line
  
  # This is a mess of a block of code. We pass each house grab the y axis. 
  #Then we look at each pair in the house. If the points are separated on 
  #the x axis with another point in between then we get rid of the line 
  #connecting and replace it with a curve
  x<-plyr::ddply(x,~HOUSE_ID,function(u){
    offset_y<-sort(unique(u$offset_y))
    plyr::ddply(u,~pair_id,function(y,offset_y){
      diff<-which(offset_y %in% y$offset_y)
      #print(diff)
      #stopifnot(length(diff)==2)
      if(length(diff)==2 & abs(diff[1]-diff[2])!=1){ # ie there is a point between these two
        #print(abs(diff[1]-diff[2]))
        y$curve=T
        y$line=F
      }
      #print(y)
      return(y)
    },offset_y)
  })
  
  seasons = plyr::ddply(x,~season,summarize,ymin=min(y_Id)-0.25,ymax=max(y_Id)+0.25,middle=mean(y_Id))
  
  if(type=="valid"){
    x<-subset(x,valid==T)
  }
  else if(type=="invalid"){
    x<-subset(x,valid==F)
    x$quality_distance=1 # makes all lines solid otherwise dashed lines represnet those with too big L1-norm

  }else if(type=="all"){
    x$quality_distance=1 # makes all lines solid
  }
  x_useful<-subset(x,snv_qualified_pair==T )
  x_lost<-subset(x,snv_qualified_pair==F) # they were lost either to not sequencing or poor titer or poor sequencing
  
  x_lines_useful<-subset(x_useful,line==T & curve==F)
  x_curves_over_useful<-subset(x_useful,line==F & curve==T)
  x_curves_both_useful<-subset(x_useful,line==T & curve==T)
  

  x_lines_useful<-plyr::ddply(x_lines_useful,~pair_id,one_for_each_plotting) # back to short form, 1 row/ pair for the lines.  offset_x is the onsets here. 1 is the first case 2 is the second
  x_curves_over_useful<-plyr::ddply(x_curves_over_useful,~pair_id,one_for_each_plotting)
  x_curves_both_useful<-plyr::ddply(x_curves_both_useful,~pair_id,one_for_each_plotting)
  
  arrow_length= 0.005
  
  transmission_plot_useful<-ggplot()+ylab("")+xlab("Onset (relative to index case)")+geom_segment(data=seasons,aes(x=-0.5,xend=-0.5,y=ymax,yend=ymin,group=season))+geom_text(data=seasons,aes(x=-1.3,y=middle,label=season,angle=0))
  if(nrow(x_lines_useful)>0){
    transmission_plot_useful<-transmission_plot_useful+geom_segment(data=x_lines_useful,aes(x=offset_x.1,xend=offset_x.2,y=offset_y.1,yend=offset_y.2,group=pair_id,linetype=factor((-2*quality_distance)+3)), # this makes the lines solid if the quality distance ==T and dashed if not
                 arrow = arrow(length = unit(arrow_length, "npc")),
                 color=cbPalette[1])
  }
  if(nrow(x_curves_over_useful)>0){
    transmission_plot_useful<-transmission_plot_useful+geom_curve(data=x_curves_over_useful,aes(x=offset_x.1,xend=offset_x.2,y=offset_y.1,yend=offset_y.2,group=pair_id,linetype=factor((-2*quality_distance)+3)),
               curvature = -0.1,
               arrow = arrow(length = unit(arrow_length, "npc")),
               color=cbPalette[1])
  }
  if(nrow(x_curves_both_useful)>0){
    transmission_plot_useful<-transmission_plot_useful+geom_curve(data=x_curves_both_useful,aes(x=offset_x.1,xend=offset_x.2,y=offset_y.1,yend=offset_y.2,group=pair_id,linetype=factor((-2*quality_distance)+3)),
               curvature = -0.4,
               arrow = arrow(length = unit(arrow_length, "npc")),
               #linetype=2,
               color=cbPalette[1])+
      geom_curve(data=x_curves_both_useful,aes(x=offset_x.2,xend=offset_x.1,y=offset_y.2,yend=offset_y.1,group=pair_id,linetype=factor((-2*quality_distance)+3)),
               curvature = -0.4,
               arrow = arrow(length = unit(arrow_length, "npc")),
               #linetype=2,
               color=cbPalette[1])
  }
  transmission_plot_useful<-transmission_plot_useful+geom_point(data=x_useful,aes(x=as.numeric(donset),y=offset_y),size=0.5)
  if(nrow(x_lost)>0){ # if at least some the data is removed then we'll add the differently colored lines
  x_lines_lost<-subset(x_lost,line==T & curve==F)
  x_curves_over_lost<-subset(x_lost,line==F & curve==T)
  x_curves_both_lost<-subset(x_lost,line==T & curve==T)
  
  # Now we just need one x axis point for each onset in the pair
  x_lines_lost<-plyr::ddply(x_lines_lost,~pair_id,one_for_each_plotting)
  x_curves_over_lost<-plyr::ddply(x_curves_over_lost,~pair_id,one_for_each_plotting)
  x_curves_both_lost<-plyr::ddply(x_curves_both_lost,~pair_id,one_for_each_plotting)
  
    transmission_plot_all<-transmission_plot_useful+geom_point(data=x_lost,aes(x=donset,y=offset_y),size=0.5)+
    geom_segment(data=x_lines_lost,aes(x=offset_x.1,xend=offset_x.2,y=offset_y.1,yend=offset_y.2,group=pair_id),
                 arrow = arrow(length = unit(arrow_length, "npc")),
                 color=cbPalette[4])
    if(nrow(x_curves_over_lost)>0){
    transmission_plot_all<-transmission_plot_all+geom_curve(data=x_curves_over_lost,aes(x=offset_x.1,xend=offset_x.2,y=offset_y.1,yend=offset_y.2,group=pair_id),
               curvature = -0.1,
               arrow = arrow(length = unit(arrow_length, "npc")),
                 color=cbPalette[4])
    }
    if(nrow(x_curves_both_lost)>0){
      transmission_plot_all<- transmission_plot_all+geom_curve(data=x_curves_both_lost,aes(x=offset_x.1,xend=offset_x.2,y=offset_y.1,yend=offset_y.2,group=pair_id),
               curvature = -0.4,
               arrow = arrow(length = unit(arrow_length, "npc")),
               linetype=2,
                 color=cbPalette[4])+
      geom_curve(data=x_curves_both_lost,aes(x=offset_x.2,xend=offset_x.1,y=offset_y.2,yend=offset_y.1,group=pair_id),
               curvature = -0.4,
               arrow = arrow(length = unit(arrow_length, "npc")),
               linetype=2,
                 color=cbPalette[4])+
    ylab("")+xlab("Onset (relative to index case)")
    }
  }  
  else{
    transmission_plot_all<-transmission_plot_useful
  }
return(transmission_plot_all+theme(legend.position = 'none',axis.line.y=element_blank(),axis.ticks.y = element_blank()) +scale_y_continuous(breaks=c())+scale_x_continuous(breaks=c(0:11),limits = c(-1.5,11)))
}
  
```

# Valid pairs
Transmission rules. These apply to all cases where 2 individuals are sick within the same household within a week of eachtoher (difference in date of onset <= 7 days).

In the event of multiple possible donors we assume the donor is the individual with symptom onset neast to the recipeient

The donor and recipeint are never have symptoms on the same day unless they are the only cases in the house. In this case we will randomize the pair and estimate a bottleneck both ways.


We'll take a look at the pairs we are refering to and then get a list of all those that quailify.

```{r,fig.align='center'}

all_seasons<-make_transmission_plot(all_pairs.tp,type='valid')

all_seasons

all_seasons_useful<-make_transmission_plot(subset(all_pairs.tp,snv_qualified_pair==T & valid==T),type='valid')
all_seasons_useful

write.csv(subset(all_pairs.tp,snv_qualified_pair==T & valid==T,
                 select=c(HOUSE_ID,ENROLLID1,ENROLLID2,
                  onset1,onset2,quality_distance,double)),
          "Figures/data/Figure3B.csv")

write.csv(subset(all_pairs.tp,snv_qualified_pair==T & valid==T),
          "Figures/data/Figure3B_all.csv")

```
This is the in set figure for some talks.

Houses of interest
```{r,eval=F}
possible_pairs.dist %>% filter(Household==T) -> household.pairs

merge(subset(all_pairs.tp,snv_qualified_pair==T),household.pairs) %>% select(HOUSE_ID1,HOUSE_ID2,SPECID1,SPECID2,L1_norm,onset1,onset2) -> pairs.df

pairs.df %>% group_by(HOUSE_ID1) %>% dplyr::summarise(pairs = length(onset1)) ->counts_house.df # warnings are about the unused columns
counts_house.df%>% filter(pairs>1)->mult_house

make_transmission_plot(subset(all_pairs.tp,snv_qualified_pair==T & valid==T&HOUSE_ID %in% c(5263,5317,1077,5228)),type='valid') ->adams_fig

pairs.df %>% filter(HOUSE_ID1 %in%c(5263,5317,1077,5228) ) %>% kable()
#require(plotly)
#ggplotly(adams_fig)
```

Here is a final summary table. These are the valid pairs
```{r,eval=T}
st <- rbind(
  data.frame(all.sum, Group = 'All', what = factor(all.sum$season, levels = all.sum$season), 
             row.names= NULL, check.names = FALSE), 
  data.frame(sequenced.sum,Group = 'Sequenced',what = factor(sequenced.sum$season, levels = sequenced.sum$season), 
             row.names = NULL,check.names = FALSE),
  data.frame(snv_hopeful.sum,Group = 'Titer>1e3',what = factor(snv_hopeful.sum$season, levels = snv_hopeful.sum$season), 
             row.names = NULL,check.names = FALSE),
  data.frame(snv.sum,Group = 'SNV qualified',what = factor(snv.sum$season, levels = snv.sum$season), 
             row.names = NULL,check.names = FALSE)
     )
require(tables)
mytable <- tabular(Heading()*what ~ Group*(`A/H1N1` +`A/H3N2`+`total`)*Heading()*(identity),data=st)
print(mytable)
#latex(mytable)
```


# SNV summary

```{r}
detach("package:dplyr")
library(dplyr)
```


### Titers

There are two samples here with NA DPI, I believe we don't have meta data on when the symptoms began. Also there are two samples with negative DPI. These are all removed in the DPI plots unless otherwise obvious.
```{r,all_titers}
titers<-subset(meta,!(is.na(DPI))) #)& DPI>=0 ) # We only want the titers where we measured a titer ( I beleive there are 2 samples here with NA). Also 2 samples were collected before symptoms - according to the meta data. That's probably a typo so we remove it here.
give.n <- function(x){ # How many samples are in this box of the box plot
  return(c(y = median(x)*1.1, label = length(x))) 
  # experiment with the multiplier to find the perfect position
}
figure1A_data<-select(titers,SPECID,
                      days.post.symptom.onset=DPI,
                      genomes.per.ul = gc_ul)

titer.p<-ggplot(figure1A_data,aes(x=as.factor(days.post.symptom.onset),
                                  y=genomes.per.ul))+
  geom_boxplot(notch = T)+
  ylab(expression(paste(Genomes,"/" ,mu,L)))+
  scale_y_log10()+xlab("Days post symptom onset")
titer.p

write.csv(figure1A_data,"./Figures/data/Figure1A.csv")
```
There are warning messages for 13 samples we did not get usable numbers back from the qPCR. They have NA in the log_copy_num column but R gives them 0 in the gc_ul. These are removed on the log scale.

### Distibution of isnv in samples

```{r,titer_over_time,eval=F}
intra_titers<-subset(all.intra,!(is.na(DPI)) & DPI>=0 & gc_ul>0) # See text above

#ggplot(intra_titers,aes(x=as.factor(DPI),y=gc_ul,group=ENROLLID))+geom_line()+geom_point()+ylab(expression(paste(genomes,"/" ,mu,L)))+scale_y_log10()+xlab("Days post symptom onset")#+geom_point(position = "jitter")
```


### Diversity in samples

```{r,snv_sample}
min.qual.o<-subset(qual,freq.var<0.5) # only looking at minor alleles original - includes all samples
min.qual<-subset(min.qual.o,!(SPECID %in% c("HS1530","MH8137","MH8390"))) # remove mixed infections

min.count.sample.o<-min.qual.o %>% group_by(SPECID) %>%
  dplyr::summarize(iSNV=length(unique(mutation)),HA_iSNV=length(which(chr=="HA"))) # How many rare mutations in the sample (SPECID)

snv_qual_meta.o<-subset(meta,snv_qualified==T)
snv_qual_meta.o<-merge(snv_qual_meta.o,min.count.sample.o,by="SPECID",all.x=T)

snv_qual_meta.o$iSNV[is.na(snv_qual_meta.o$iSNV)]<-0 # these are the ones with no diversity
snv_qual_meta.o$HA_iSNV[is.na(snv_qual_meta.o$HA_iSNV)]<-0

plot.median <- function(x) {
  m <- median(x)
  c(y = m, ymin = m, ymax = m)
}

ggplot(snv_qual_meta.o,aes(y=iSNV,x=as.factor(vaccination_status)))+geom_dotplot(stackdir = "center",binaxis = 'y',binwidth = 1,dotsize = 0.5)+stat_summary(fun.data="plot.median", geom="errorbar", colour="black", width=0.95, size=0.5)+scale_x_discrete(labels=c("Not Vaccinated","Vaccinated"))+xlab("")

#wilcox.test(snv_qual_meta.o$iSNV~snv_qual_meta.o$vaccination_status) 
```

```{r}
figure1B_data<-snv_qual_meta.o %>% select(days.post.symptom.onset=DPI,iSNV)
isnv_by_day.p<-ggplot(snv_qual_meta.o,aes(x=as.factor(DPI),y=iSNV))+geom_boxplot()+xlab("Day post symptom onset")#+geom_dotplot(stackdir = "center",binaxis = 'y',binwidth = 1,dotsize = 0.5)+stat_summary(fun.data="plot.median", geom="errorbar", colour="black", width=0.95, size=0.5)
write.csv(figure1B_data,"./Figures/data/Figure1B.csv")
isnv_by_day.p

isnv_by_isolate.p<-ggplot(snv_qual_meta.o,aes(x=iSNV))+geom_histogram(color="white",binwidth = 1)+xlab("iSNV in isolate") +ylab("Isolates")



ggplot(snv_qual_meta.o,aes(x=as.factor(pcr_result),y=iSNV))+geom_dotplot(stackdir = "center",binaxis = 'y',binwidth = 1,dotsize = 0.5)+stat_summary(fun.data="plot.median", geom="errorbar", colour="black", width=0.95, size=0.5)+xlab("Strain")

isnv_titer<-ggplot(snv_qual_meta.o,aes(x=gc_ul,y=iSNV))+geom_point()+scale_x_log10()+xlab(expression(paste(Genomes,"/" ,mu,L)))
isnv_titer
```
### Frequency distribution
```{r,frequency_distribution}


classes<-min.qual %>% group_by(class_factor) %>%
  dplyr::summarize(mutations=length(mutation)) # class factor is is Nonsym if in any open reading frame the mutation is Nonsym.
kable(classes)
write_to_summary("Ns/S:",
                 classes$mutations[classes$class_factor=="Nonsynonymous"]/classes$mutations[classes$class_factor=="Synonymous"])

figure1CD_data<-min.qual %>% select(SPECID,chr,pos,freq.var,class_factor)

freq_hist.p<-ggplot(figure1CD_data,aes(x=freq.var,fill=class_factor))+
  geom_histogram(color="white",binwidth=.05,position=position_dodge(),
                 boundary = 0.02)+
  xlab("Frequency")+ylab("iSNV")+
  scale_fill_manual(name="",values=cbPalette[c(1,4)])+
  theme(legend.position = c(0.5, 0.5))

freq_hist.p

write.csv(figure1CD_data,"./Figures/data/Figure1C_D.csv")

freq_hist.d<-ggplot_build(freq_hist.p)
freq_hist.d$data[[1]]->bins
bins$bin<-rep(1:10,each=2)

bin_ratio<- bins %>% group_by(bin) %>%
  dplyr::summarize(ratio = count[2]/count[1]) # NS/S

bin_ratio

write_to_summary("Max Ns/S:",max(bin_ratio$ratio))

```


`r classes$mutations[classes$class_factor=="Synonymous"]/sum(classes$mutations)`

### Distribution across the genome
```{r,isnv_genome}
min.qual$chr<-factor(min.qual$chr,levels = rev(c("PB2","PB1","PA","HA","NP","NR","M","NS"))) # Set the segments as factors with PB2 on top
chrs<-read.csv("../data/reference/segs.csv",stringsAsFactors = T) # get the start and stop of each OR for each segment (2014-2015 used as reference)

chrs$chr<-factor(chrs$chr,levels=levels(min.qual$chr)) # set factors on the is meta data
genome_loc.p<-ggplot(min.qual,aes(x=pos,y=chr))+
  geom_point(aes(color=class_factor),shape=108,size=5)+
  geom_segment(data=chrs,aes(x = start, y = chr, xend = stop, yend = chr))+
  ylab("")+
  xlab("")+
  scale_color_manual(name="",values=cbPalette[c(1,4)])+
  theme(axis.ticks =element_blank(),
        axis.line.x = element_blank(), axis.line.y=element_blank())+
  scale_x_continuous(breaks=c())+
  theme(legend.position = "none")
genome_loc.p
```


### Distribution across Individuals - using every sample

These will need to be rare in mulitple individuals to show up here at >1
```{r,mutations_per_sample}
give.n.atCount <- function(x){ # How many samples are in this box of the box plot
  return(c(y = length(x)*1.1, label = length(x))) 
  # experiment with the multiplier to find the perfect position
}
min.count<- min.qual %>% group_by(chr,pos,var,pcr_result,season) %>%
  dplyr::summarize(counts=length(unique(ENROLLID))) # In how many people (ENROLLID) is the muation found. It would have to be minor in both people to count in this plot. The chr pos var is used so that called and infered variants of the same var are counted together.
ggplot(min.count,aes(x=counts))+geom_histogram(color="white",binwidth=1)+xlab("Number of individuals")+ylab("iSNV")+stat_bin(aes(y=..count.., label=..count..), geom="text", vjust=-.5) +scale_y_log10()


min.count %>% subset(counts==1) %>% nrow()->only_once
min.count %>% subset(counts==2) %>% nrow()->only_twice
min.count %>% subset(counts==3) %>% nrow()->only_thrice

write_to_summary("unique iSNV n:",only_once)
write_to_summary("unique iSNV %:",only_once/(only_once+only_twice+only_thrice))
write_to_summary("twice iSNV %:",only_twice/(only_once+only_twice+only_thrice))
write_to_summary("thrice iSNV %:",only_thrice/(only_once+only_twice+only_thrice))
write_to_summary("multiple isolates iSNV n:",only_twice+only_thrice)

```
These are the mutations found in multiple individuals
```{r}
min.qual<-mutate(min.qual,scratch = paste(chr,pos,chr,season,pcr_result,sep="."))
min.count <-mutate(min.count,scratch = paste(chr,pos,chr,season,pcr_result,sep="."))
multiple<-subset(min.qual,scratch %in% min.count$scratch[min.count$counts>1])

min.qual<-subset(min.qual,select=-c(scratch))
min.count<-subset(min.count,select=-c(scratch))


multiple %>% subset(class_factor=="Nonsynonymous") %>% .$mutation %>%
  unique()->mult.NS
write_to_summary("NS mulitple isolates iSNV n:",paste(mult.NS,collapse = ", "))

ggplot(multiple,aes(x=pos,y=chr))+geom_point(aes(color=class_factor),shape=108,size=5)+geom_segment(data=chrs,aes(x = start, y = chr, xend = stop, yend = chr))+ylab("")+xlab("")+scale_color_manual(name="",values=cbPalette[c(1,4)])+ theme(axis.ticks =element_blank(),axis.line.x = element_blank(),axis.line.y=element_blank())+scale_x_continuous(breaks=c())+theme(legend.position = "none")

genome_loc.p.dots<-genome_loc.p + geom_point(data = multiple, aes(x=pos,y=as.numeric(chr)+0.3,color=class_factor),size=1,shape=6)
genome_loc.p.dots
```
These counts don't sum to the total above, but that is because this is looking at individuals above is looking at all sequenced samples (multiple/person) sometimes. If I sum these counts over SPECID then the sums are equal.

### Diversity in by vaccination

```{r,snv_sample}
min.count.sample<-min.qual %>% group_by(SPECID) %>%
  dplyr::summarize(iSNV=length(unique(mutation)),HA_iSNV=length(which(chr=="HA"))) # How many rare mutations in the sample (SPECID)

snv_qual_meta<-subset(meta,snv_qualified==T)
snv_qual_meta<-merge(snv_qual_meta,min.count.sample,by="SPECID",all.x=T)

snv_qual_meta$iSNV[is.na(snv_qual_meta$iSNV)]<-0 # these are the ones with no diversity
snv_qual_meta$HA_iSNV[is.na(snv_qual_meta$HA_iSNV)]<-0

plot.median <- function(x) {
  m <- median(x)
  c(y = m, ymin = m, ymax = m)
}

ggplot(snv_qual_meta,aes(y=iSNV,x=as.factor(vaccination_status)))+geom_dotplot(stackdir = "center",binaxis = 'y',binwidth = 1,dotsize = 0.5)+stat_summary(fun.data="plot.median", geom="errorbar", colour="black", width=0.95, size=0.5)+scale_x_discrete(labels=c("Not Vaccinated","Vaccinated"))+xlab("")

#wilcox.test(snv_qual_meta$iSNV~snv_qual_meta$vaccination_status) 
```

### Distribution of snv in samples (Could be multiple samples/person)

```{r}
quantile(snv_qual_meta$iSNV)->iSNV_quantile
iSNV_quantile
mean(snv_qual_meta$iSNV)

nrow(subset(snv_qual_meta,iSNV<10 & snv_qualified==T)) ->less_10
nrow(subset(snv_qual_meta,iSNV>10 & snv_qualified==T)) -> greater_10

write_to_summary("SPECID <10 iSNV:",less_10)
write_to_summary("SPECID more 10 iSNV:",greater_10)
write_to_summary("Median iSNV:",paste(iSNV_quantile[3],collapse = ""))
write_to_summary("IQR iSNV:",paste(iSNV_quantile[2],iSNV_quantile[4],collapse = "-"))
```


```{r}
isnv_vaccination<-ggplot(snv_qual_meta,aes(y=iSNV,x=as.factor(vaccination_status)))+geom_dotplot(stackdir = "center",binaxis = 'y',binwidth = 1,dotsize = 0.5)+stat_summary(fun.data="plot.median", geom="errorbar", colour="red", width=0.5, size=0.5) +xlab("") + scale_x_discrete(labels = c("Not vaccinated","Vaccinated"))
isnv_vaccination
#wilcox.test(snv_qual_meta$HA_iSNV~snv_qual_meta$vaccination_status) 

```

## Codon pos

```{r}
codon_pos<- min.qual %>% select(ENROLLID,SPECID,season,onset,pcr_result,chr,mutation,freq.var,
                                OR,coding_pos,Ref_AA,Var_AA) %>%
          mutate(OR = gsub("\\[","",OR),
                 coding_pos = gsub("\\[","",coding_pos),
                 Ref_AA = gsub("\\[","",Ref_AA),
                 Var_AA = gsub("\\[","",Var_AA))%>%
            mutate(OR = gsub("\\]","",OR),
                 coding_pos = gsub("\\]","",coding_pos),
                 Ref_AA = gsub("\\]","",Ref_AA),
                 Var_AA = gsub("\\]","",Var_AA))%>%
            mutate(OR = gsub("'","",OR),
                 coding_pos = gsub("'","",coding_pos),
                 Ref_AA = gsub("'","",Ref_AA),
                 Var_AA = gsub("'","",Var_AA))%>%
  # split the multiple open reading frames 
            separate(coding_pos,c("coding1","coding2"),sep=",",extra = "merge",fill="right") %>%
            separate(OR,c("OR1","OR2"),sep=",",extra = "merge",fill="right")%>%
            separate(Ref_AA,c("Ref_AA1","Ref_AA2"),sep=",",extra = "merge",fill="right") %>%
            separate(Var_AA,c("Var_AA1","Var_AA2"),sep=",",extra = "merge",fill="right") %>%
  
  # Bring it back together on different lines
    # calucate codon_pos
    mutate(codon_pos= as.numeric(coding1) %% 3,
           codon_pos= ifelse(codon_pos==0,yes = 3,no = codon_pos))
  
ggplot(codon_pos,aes(x=codon_pos))+geom_histogram()+scale_x_continuous(breaks=c(1:3))+
  xlab("Position in codon")+ylab("iSNV")#+facet_wrap(~chr)
```



# Figure 1

```{r}
require(cowplot)

fig_1<-plot_grid(titer.p,isnv_by_day.p,freq_hist.p, genome_loc.p, labels = c("A", "B", "C", "D"), ncol = 2,align = c("v","h"))#+draw_label("DRAFT!", angle = 45, size = 80, alpha = .2)

save_plot("./Figures/Figure1.pdf", fig_1,
          ncol = 2, # we're saving a grid plot of 2 columns
          nrow = 2, # and 2 rows
          # each individual subplot should have an aspect ratio of 1.3
          base_aspect_ratio = 1.3
          )
embed_fonts("./Figures/Figure1.pdf")
fig_1
```


Separate Panels

```{r}
save_plot("./Figures/Figure1A.pdf", titer.p,
          base_aspect_ratio = 1.3)
embed_fonts("./Figures/Figure1A.pdf")
#titer.pg<-ggplot_build(titer.p)

save_plot("./Figures/Figure1B.pdf", isnv_by_day.p,
          base_aspect_ratio = 1.3)
embed_fonts("./Figures/Figure1B.pdf")

save_plot("./Figures/Figure1C.pdf", freq_hist.p,
          base_aspect_ratio = 1.3)

embed_fonts("./Figures/Figure1C.pdf")
save_plot("./Figures/Figure1D.pdf", genome_loc.p,
          base_aspect_ratio = 1.3)

save_plot("./Figures/Figure1D2.pdf", genome_loc.p.dots,
          base_aspect_ratio = 1.3)
embed_fonts("./Figures/Figure1D2.pdf")
save_plot("./Figures/isnv_by_isolate.pdf", isnv_by_isolate.p,
          base_aspect_ratio = 1.3)
```


# Figure 3
```{r}
fig_3<-plot_grid(l1norm.p_tp,all_seasons_useful , labels = c("A", "B"), ncol = 1,align = c("h"),rel_heights=c(1,3))#+draw_label("DRAFT!", angle = 45, size = 80, alpha = .2)

save_plot("./Figures/Figure3.pdf", fig_3,
          ncol = 1, # we're saving a grid plot of 1 columns
          nrow = 2, # and 2 rows
          base_height = 6,
          # each individual subplot should have an aspect ratio of 1.3
          base_aspect_ratio = 1.3
          )
embed_fonts("./Figures/Figure3.pdf")
fig_3

```

```{r}
save_plot("./Figures/Figure3A.pdf", l1norm.p_tp,
          base_aspect_ratio = 1.3,
          base_height = 6)
embed_fonts("./Figures/Figure3A.pdf")

save_plot("./Figures/Figure3B.pdf", all_seasons_useful,
          base_aspect_ratio = 1.3,
          base_height = 6)
embed_fonts("./Figures/Figure3B.pdf")

```


#Supplemental Figure 4

```{r}
sup_fig_1<-plot_grid(isnv_titer,isnv_vaccination, labels = c("A", "B"), ncol = 2,align = c("v","h"))#+draw_label("DRAFT!", angle = 45, size = 80, alpha = .2)

save_plot("./Figures/Supplemental_Figure4.pdf", sup_fig_1,
          ncol = 2, # we're saving a grid plot of 2 columns
          nrow = 1, # and 1 row
          # each individual subplot should have an aspect ratio of 1.3
          base_aspect_ratio = 1.3
          )
embed_fonts("./Figures/Supplemental_Figure4.pdf")
sup_fig_1
```

```{r,eval=T}
write.csv(x = snv_qual_meta,"../data/processed/secondary/meta_snv_qual.csv")
```

# Looking at the outliers

Let's take a look at the samples with many snv.


```{r}

require(ggjoy)
outliers<-subset(min.count.sample.o,iSNV>10)

outliers.snv<-subset(min.qual.o,SPECID %in% outliers$SPECID)

ggplot(outliers.snv,aes(x=freq.var))+geom_histogram(aes(fill=SPECID),position='dodge',binwidth = 0.05)#+scale_fill_manual(values=wes_palette("GrandBudapest2"))
ggplot(outliers.snv,aes(x=freq.var,y= as.factor(SPECID),height = ..density..))+geom_joy(scale = 4)
```
This looks like mixed infections. We find many mutations at similar frequencies.

# Antigenic sites


```{r}
antigenic<-read_csv("../data/processed/secondary/antigenic_isnv.csv")
antigenic_counts<-antigenic %>% group_by(mutation) %>% summarize(found = length(mutation))
kable(filter(antigenic,mutation %in% 
               antigenic_counts$mutation[antigenic_counts$found>1]))

min.qual<-left_join(min.qual,antigenic,by = c("HOUSE_ID","ENROLLID","SPECID","mutation","pcr_result","vaccination_status","DPI","Ref_AA","Var_AA"))
min.qual$Antigenic[is.na(min.qual$Antigenic)]<-"None"
HA_NS<-filter(min.qual,class_factor=="Nonsynonymous",chr=="HA")
require(ggbeeswarm)
ggplot(HA_NS, aes(y=freq.var.x,x=Antigenic=="None"))+geom_quasirandom(varwidth = TRUE)+stat_summary(fun.data="plot.median", geom="errorbar", colour="red", width=0.55, size=0.5)+ylab("iSNV frequency")+xlab(label = "")+scale_x_discrete(labels = c("Antigeic site","NonAntigenic site"))+scale_y_continuous(limits=c(0,0.5))

wilcox.test(HA_NS$freq.var.x[which(HA_NS$Antigenic!="None")],
            HA_NS$freq.var.x[which(HA_NS$Antigenic=="None")],alternative = "greater")
```
For the whole genome

```{r}
All_NS<-filter(min.qual,class_factor=="Nonsynonymous")
ggplot(All_NS, aes(y=freq.var.x,x=Antigenic=="None"))+geom_quasirandom()+stat_summary(fun.data="plot.median", geom="errorbar", colour="red", width=0.55, size=0.5)+ylab("iSNV frequency")+xlab(label = "")+scale_x_discrete(labels = c("Antigeic site","NonAntigenic site"))

wilcox.test(All_NS$freq.var.x[which(All_NS$Antigenic!="None")],
            All_NS$freq.var.x[which(All_NS$Antigenic=="None")],alternative = "greater")
```




# Global dynamics

```{r}
require(lubridate)
nextflu<-read.table("../data/processed/secondary/global_freq.csv",header = T)

require(tidyverse)
require(directlabels)

nextflu %>% select(-HA1.307R.1)%>% gather(mutation,frequency,-x) ->nextflu.l # We found this one twice.

nextflu.l %>% mutate(mutation=gsub("(.*)\\.(.*)","\\1:\\2",mutation))->nextflu.l

minor %>% filter(pcr_result=="A/H3N2", !is.na(Antigenic)) ->H3_minor

H3_minor %>% subset(H3_name %in% nextflu.l$mutation & pcr_result=="A/H3N2",
                 select = c(collect,SPECID,H3_name,freq.var)) %>%
  mutate(collect=decimal_date(collect))->collection_points

kable(collection_points)


antigenic_nextflu.l<-inner_join(nextflu.l,collection_points,by=c("mutation" = "H3_name"))

nextflu.p<-ggplot()+
  geom_line(data = filter(antigenic_nextflu.l,x>=collect),
            aes(x=x,y=frequency,color=mutation),alpha=1)+
  ylab("Global Frequency")+xlab("Year")+
  scale_x_continuous(breaks = seq(2005,2018,by=2))+
  geom_vline(xintercept =collection_points$collect,linetype=2,alpha=0.5)
nextflu.p


#nextflu.p<-direct.label(nextflu.p,"angled.boxes")

#nextflu.p<-direct.label(nextflu.p,c("first.qp"))
nextflu.p<-direct.label(nextflu.p,c("last.qp"))
nextflu.p+geom_line(data = filter(antigenic_nextflu.l,x<collect),
            aes(x=x,y=frequency,color=mutation),alpha=0.3)


```