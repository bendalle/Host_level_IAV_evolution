---
title: "Transmission models"
author: "JT McCrone"
date: "4/7/2017"
output: github_document
---


```{r,echo=F}
require(knitr)
require(ggplot2)
require(magrittr)
require(tidyverse)
if(!("package:tidyverse" %in% search())){
  require(dplyr)
  require(tidyr)
  require(purrr)
  require(readr)
  require(rlang)
}
require(HIVEr)
require(extrafont)
require(wesanderson)
require(grid)
require(ggplot2)

set.seed(42) # Set seed so randomization is reproducible


set.seed(42) # Set seed so randomization is reproducible
opts_chunk$set(fig.align="center",warning=FALSE,tidy=T,cache = T,echo=F)
theme_set(new = theme_classic()+ theme(
axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
axis.line.y = element_line(colour ='black',size=0.5,linetype='solid'),
text=element_text(family="Arial",size = 18))) # to make nice plots

# A couple color palette options.
#cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
cbPalette <- wes_palette("Zissou")
####### Write to summary results file ######
write_to_summary<-function(line_pattern,value){
  file = readLines("./results.table.tsv")
  line_pattern_regex = paste0("^",line_pattern)
  line = grep(line_pattern_regex,file)
  file[line] = paste0(line_pattern,"\t",value)
  writeLines(file,"./results.table.tsv")
}
```


```{r}
# trans_freq<-read.csv("./transmission_pairs_freq.poly.donor.csv") # Read in the freq.variant calls from the transmission setup Rmd
# trans_freq.comp<-polish_freq(trans_freq,freq1,0.02)
# trans_freq.comp$found<-trans_freq.comp$freq2>0.02 # was it found in the second sample

meta<-read_csv("../data/reference/all_meta.sequence_success.csv")

trans_freq.comp <- read_csv("../data/processed/secondary/transmission_pairs_freq.poly.donor.csv")

# Add gc_ul
trans_freq.comp<-mutate(trans_freq.comp,gc_ul1 = meta$gc_ul[match(SPECID1,meta$SPECID)],
                        gc_ul2 = meta$gc_ul[match(SPECID2,meta$SPECID)])


```
# Presence/Absence model

Let $A_1$ and $A_2$ be a alleles in the donor. Then there are three possible outcomes of transmission. Either $A_1$ is transmitted, $A_2$ is transmitted, or both $A_1$ and $A_2$ are transmitted. The probability of only one allele being transmitted (let's call it $A_i$) given a bottleneck size of $N_b$ is 
\[
P(A_i) = f_i^{N_b}
\]

Where $p_i$ is the frequency of the allele in the donor. In otherwords this is simply the probability of only drawing $A_i$ in $N_b$ draws.

The probability of both alleles being transmitted is given by

\[
P(A_1,A_2) = 1- \big(f_1^{N_b}+f_2^{N_b}\big)
\]

where $f_1$ and $f_2$ are the frequencies of the alleles respectively. This is simply the probability of not picking only $A_1$ or only $A_2$ in $N_b$ draws.

We can then define the probability of observing the data at each polymorphic site $j$ as $P_j$ where $P_j=P(A_i)$ if only one allele is transmitted and $P_j=P(A_1,A_2)$ if two alleles are transmitted. 

The  likelihood of a bottleneck size $N_b$ is then given by

\[
L(N_b) = \prod^j P_j
\]

or the probability of observing the data at each polymorphic site. Thus the log likelihood is given by

\[
\text{log}(L(N_b)) = \sum^j\text{log}(P_j)
\]

### Fitting the Presence/Absence model

In this fit we take the minority frequency to the correct and set the major frequency to 1-minority

```{r}

pa_Nb<-trans_fit(trans_freq.comp,l=seq(0.01,10,0.01),Nb_max=100,model="PA",
                 threshold=NULL,acc=NULL,
                 pair_id)
  
pa_Nb_sum<- pa_Nb %>% group_by(pair_id) %>% do(model_summary(.) )
pa_total_fit<-trans_fit(trans_freq.comp,l=seq(0.01,10,0.01),Nb_max=100,model="PA",
                 threshold=NULL,acc=NULL)
pa_fit_sum<-model_summary(pa_total_fit)
pa_fit_sum

write_to_summary("P-A Nb:",pa_fit_sum$mean_Nb)
write_to_summary("P-A lambda:",pa_fit_sum$lambda)
write_to_summary("P-A CI:",paste(pa_fit_sum$lower_95,pa_fit_sum$upper_95,collapse = "-"))


prob_above_5 <-1-sum(dzpois(c(1,2,3,4,5),pa_fit_sum$lambda))
write_to_summary("P-A prob >5",prob_above_5)
```

### Log likelihood plot
```{r,eval=T}
lambda_to_mean<-function(x){
  x/(1-exp(-1*x))
}
pa_ll.p<-ggplot(pa_total_fit,aes(x=lambda_to_mean(lambda),y=LL))+geom_point()+ylab("Log Likelihood")+xlab("Average Bottleneck size")+scale_x_continuous(breaks=c(1:10))
pa_ll.p
require(cowplot)

```

### Fits by pair
 For fun
```{r,fig.height=6}
pa_Nb_sum<-pa_Nb_sum[order(pa_Nb_sum$mean_Nb,decreasing = T),]
pa_Nb_sum$y = 1:nrow(pa_Nb_sum)

ggplot()+geom_point(data=pa_Nb_sum,aes(y=y,x=lambda_to_mean(lower_95)),shape=108,size=4,color=cbPalette[2])+
  geom_point(data=pa_Nb_sum,aes(y=y,x=lambda_to_mean(upper_95)),shape=108,size=4,color=cbPalette[2])+
  geom_point(data=pa_Nb_sum,aes(y=y,x=mean_Nb),shape=108,size=5,color=cbPalette[5])+
  geom_segment(data=pa_Nb_sum,aes(x=lambda_to_mean(lower_95),xend=lambda_to_mean(upper_95),y=y,yend=y),color=cbPalette[2])+
  theme(axis.ticks.y =element_blank(),axis.line.y=element_blank())+
  scale_y_continuous(breaks=c())+ylab("Transmission pair")+xlab("Bottleneck")+
  scale_x_continuous(limits = c(0,10.1))
```

By pair table

```{r}
pa_t<-pa_Nb_sum %>% mutate(
  CI = paste0(lower_95,"-",upper_95),
  lambda = paste0(lambda," (",CI,")")
  ) %>%
  select(pair_id,lambda,mean_Nb,pair_id)
pa_t<-left_join(pa_t,
                select(trans_freq.comp,pair_id,ENROLLID1,ENROLLID2,
                       collect1,collect2,transmission))%>%
        distinct(pair_id, .keep_all = TRUE) %>%
        dplyr::rename(donor_sample = collect1, recipient_sample=collect2,estimated_transmission_date=transmission) %>% select(-pair_id,-ENROLLID1,-ENROLLID2)

write.csv(pa_t,"./pa_bottlenecks_by_pair.csv")
```
### Simulation


```{r}
sim_plot<-function(variant.df,sim_trans,force_0=F){ # variants is the frequency comparision data frame sim_trans is the simulated data frame
if(force_0){
  logit<-glm(formula =found~freq1-1,
             family=binomial(logit),data=variant.df )# get the data trend line
   variant.df$prob<-logit$fitted.values # this is the data line
   # Add the point at 0 predicting this model with freq1=0 yields 0
   inter<-variant.df[1,]
   inter$freq1<-0
   inter$prob<-0
   inter$found<-F
   variant.df<-rbind(variant.df,inter)

}else{
logit<-glm(formula =found~freq1,family=binomial(logit),data=variant.df ) # get the data trend line
 variant.df$prob<-logit$fitted.values # this is the data line
}
 

trans.area=plyr::ddply(sim_trans,~freq1,summarize,low.95=quantile(prob,na.rm=T,probs=0.025),high.95=quantile(prob,na.rm=T,probs=0.975),low.50=quantile(prob,na.rm=T,probs=0.25),high.50=quantile(prob,na.rm=T,probs=0.75)) # Get the quanitles for each data point

trans.sim_plot=ggplot()+
  geom_ribbon(data=trans.area,aes(x=freq1,ymin=low.95,ymax=high.95),
              alpha=0.6,fill=cbPalette[5])+
  geom_ribbon(data=trans.area,aes(x=freq1,ymin=low.50,ymax=high.50),
              alpha=0.9,fill=cbPalette[5])+
  xlab("")+ylab("Probability transmitted")+
  geom_point(data=variant.df,aes(x=freq1,y=as.numeric(found)),alpha=0.1)+
  geom_line(data=variant.df,aes(x=freq1,y=prob))+xlab("Frequency in donor")#+scale_fill_discrete(name="Average bottleneck")

  return(trans.sim_plot)
}
```

```{r,eval=T}
sim_trans_pa<-simulations(data=trans_freq.comp,runs = 1000,lambda = pa_fit_sum$lambda,
                          pa_sim,threshold = NULL,acc = NULL,pair_id) # presence/absence
```

```{r}
pa_sim_plot<-sim_plot(trans_freq.comp,sim_trans_pa)

write.csv(rename(sim_trans_pa,frequency.in.donor=freq1,
                 probability.of.transmission=prob),"Figures/data/Figure3D.area.csv")
pa_sim_plot
```

# all transmitted >10%

What if all variants above 10% were transmitted? What would the bottleneck size be?

```{r}
very_good.comp<-trans_freq.comp
very_good.comp$found[very_good.comp$freq1>=0.1] <- TRUE
logit<-glm(formula =found~freq1,family=binomial(logit),data=very_good.comp ) # get the data trend line
 very_good.comp$prob<-logit$fitted.values 
ggplot()+ ylab("Probability transmitted")+
  geom_point(data=very_good.comp,aes(x=freq1,y=as.numeric(found)),alpha=0.1)+
  geom_line(data=very_good.comp,aes(x=freq1,y=prob))+xlab("Frequency in donor")
 
 
```


```{r}

vg_total_fit<-trans_fit(very_good.comp,l=seq(0.01,10,0.01),Nb_max=100,model="PA",
                 threshold=NULL,acc=NULL)
vg_fit_sum<-model_summary(vg_total_fit)
vg_fit_sum

```

```{r}
ggplot(filter(vg_total_fit,lambda>3,lambda<10),aes(x=lambda_to_mean(lambda),y=LL))+geom_point()+ylab("Log Likelihood")+xlab("Average Bottleneck size")+scale_x_continuous(breaks=c(1:10))

```

```{r,eval=T}
vg_sim_trans_pa<-suppressWarnings(simulations(data=very_good.comp,runs = 10,lambda = vg_fit_sum$lambda,
                          pa_sim,threshold = NULL,acc = NULL,pair_id))

```

```{r}
vg_sim_plot<-sim_plot(very_good.comp,vg_sim_trans_pa)

#write.csv(sim_trans_pa,"Figures/data/Figure4B.area.csv")
vg_sim_plot
```
This sort of makes sense. If there was a larger bottleneck then we would expect the low - frequency variants would have higher probabilities of transmission as well.

# No frequency cut off
```{r}
no_cut.trans_freq.comp<-read_csv("../data/processed/secondary/no_cut_transmission_pairs_freq.poly.donor.csv")
```

```{r}

no_cut.pa_total_fit<-suppressWarnings(trans_fit(no_cut.trans_freq.comp,l=seq(1,200,1),
                               Nb_max=300,model="PA",
                               threshold=NULL,acc=NULL))
no_cut.pa_fit_sum<-model_summary(no_cut.pa_total_fit)
no_cut.pa_fit_sum 

```
The warning reduces to the 3 sites wher ethe total frequency is very close to 99%. Our assumption that major allele = 1-minor should hold just fine.
```{r}
no_cut.trans_freq.comp %>% group_by(pair_id,chr,pos) %>% summarize(sum.freq = sum(freq1))->x
x %>% filter(sum.freq<0.99)
semi_join(no_cut.trans_freq.comp,filter(x,sum.freq<0.99))->y
select(y,SPECID1,SPECID2,HOUSE_ID,chr,pos,ref,var,freq1,freq2)

```


### Log likelihood plot
```{r,eval=T}

no_cut.pa_ll.p<-ggplot(filter(no_cut.pa_total_fit,lambda>110,lambda<125),aes(x=lambda_to_mean(lambda),y=LL))+geom_point()+ylab("Log Likelihood")+xlab("Average Bottleneck size")#+scale_x_continuous(limits=c(100,90),breaks=c(70:90))+scale_y_continuous(limits=c(-4300,-4150))
no_cut.pa_ll.p

```


## No cut simulation
```{r,eval=T}
no_cut_sim_trans_pa<-suppressWarnings(simulations(data=no_cut.trans_freq.comp,runs = 1000,lambda = no_cut.pa_fit_sum$lambda,
                          pa_sim,threshold = NULL,acc = NULL,pair_id))
# The warnings are about glm.fit hitting 1 or 0 looking at the data it's 1.
# presence/absence
```

```{r}
no_cut_pa_sim_plot<-sim_plot(no_cut.trans_freq.comp,no_cut_sim_trans_pa,force_0 = T)

#write.csv(sim_trans_pa,"Figures/data/Figure4B.area.csv")
no_cut_pa_sim_plot+scale_x_log10()
```

# No cut no infer
Let's get rid of sites with infered minor alleles.
```{r}
no_cut.trans_freq<-read_csv("../data/processed/secondary/no_cut_trans_freq.csv", 
              col_types = list(
                 ENROLLID1= col_character(),
                 ENROLLID2= col_character(),
                 SPECID1 = col_character(),
                 SPECID2 = col_character(),
                 pair_id = col_double()))
no_cut_no_infer<- no_cut.trans_freq %>% group_by(SPECID1,SPECID2,pair_id,chr,pos) %>%
  mutate(minor_infer = ifelse( 
    # There is one site where the minor allele is not the reference. Then it goes away. 
    # This gives a length of 0 and the minor is not infered so it's False. Otherwise
    # we set the minor_infered column to the output of the comparison.
    length(which(ref==var)==which(freq1==min(freq1)))==0,
    F,
    (which(ref==var)==which(freq1==min(freq1))&min(freq1)<0.1)
  )) %>%
  filter(minor_infer==F)


nc_ni_tv_plot<-ggplot(no_cut_no_infer,aes(freq1,freq2))+geom_point()
nc_ni_tv_plot
ggplot(no_cut_no_infer,aes(freq1,freq2))+geom_point()+
  scale_y_log10(breaks=c(0.0001,0.001,0.01,0.1,1))+
  scale_x_log10(c(0.0001,0.001,0.01,0.1,1))

```


```{r}
no_cut_no_infer.comp<- no_cut.trans_freq.comp %>% group_by(SPECID1,SPECID2,pair_id,chr,pos) %>%
  mutate(minor_infer = ifelse( 
    # There is one site where the minor allele is not the reference. Then it goes away. 
    # This gives a length of 0 and the minor is not infered so it's False. Otherwise
    # we set the minor_infered column to the output of the comparison.
    length(which(ref==var)==which(freq1==min(freq1)))==0,
    F,
    (which(ref==var)==which(freq1==min(freq1))&min(freq1)<0.1)
  )) %>%
  filter(minor_infer==F)

```

```{r}

logit<-glm(formula =found~freq1,family=binomial(logit),data=no_cut_no_infer.comp ) # get the data trend line
 no_cut_no_infer.comp$prob<-logit$fitted.values 
ggplot()+ ylab("Probability transmitted")+
  geom_point(data=no_cut_no_infer.comp,aes(x=freq1,y=as.numeric(found)),alpha=0.1)+
  geom_line(data=no_cut_no_infer.comp,aes(x=freq1,y=prob))+xlab("Frequency in donor")
 
 
```

```{r}
nc_ni.pa_total_fit<-suppressWarnings(trans_fit(no_cut_no_infer.comp,l=seq(0.01,10,0.01),
                               Nb_max=100,model="PA",
                               threshold=NULL,acc=NULL))
nc_ni.pa_fit_sum<-model_summary(nc_ni.pa_total_fit)
nc_ni.pa_fit_sum 
```


```{r,eval=T}
nc_ni.sim_trans_pa<-simulations(data=no_cut_no_infer.comp,runs = 1000,
                          lambda = nc_ni.pa_fit_sum$lambda,
                          pa_sim,threshold = NULL,acc = NULL,pair_id) # presence/absence
```

```{r}
nc_ni.pa_sim_plot<-sim_plot(no_cut_no_infer.comp,nc_ni.sim_trans_pa)

nc_ni.pa_sim_plot


```



# Beta binomial model

The Beta binomial model is explained in detail in Leonard \emp{et al.}. It is similar to the presence/absence model in that transmission is modeled as a simple sampling process; however, it loosens the assumption that the frequencies in the recipient are constant overtime. Instead frequencies of transmitted variants are allowed to change between transmission and sampling according the a beta distribution. The distribution is not dependent on the amount of time that passes between transmission and sampling, and the frequency in the donor is assumed to be the same between sampling and transmission.

The equations below are very similar to those present by Leonard \emp{et al.} with two exceptions. (1) We fit a distribution to the bottleneck sizes in our cohort, and (2) because we know our sensitivity to detect rare variants based on the expected frequency of the iSNV and the titer of the sample we can include the possiblity that iSNV are transmitted but are missed due to less than perfect sensitivity.



\[
L(N_b)_i=\sum_{k=0}^{N_b}\text{p_beta}\Big( _{R,i}|k,N_b-k\Big)\text{p_bin}\Big(k|N_b,v_{D,i}\Big)
\]

and

I will start with the most conservative assumption. We will always round the titer and frequency down to the nearest standard and apply that accuracy. Also I'm assuming the accuracy is perfect in the donor.

So now the likelihood function of lost variants is given by


\[
L(N_b)_i=\sum_{k=0}^{N_b}\Big[\text{p_beta_cdf}\Big( v_{R,i}<T|k,N_b-k\Big)\text{p_bin}\Big(k|N_b,v_{D,i}\Big)+\sum_{f_i}^{[0.02,0.05,0.1)}\text{p_beta}\big(f_i<v_{R,i}<f_{i+1}\big|k,N_b-k\big)\text{p_bin}\Big(k|N_b,v_{D,i}\Big)\big(1-\text{sensitivity}|\text{titer}_R,f_i)\Big]
\]
In other words what is the probability the (variant was not transmitted or transmitted but remains <2%) or ( the variant was transmitted and is present within a given frequency range and we don't find it given the lower end of that frequency range and the titer of the sample.)



## Fitting 

```{r}
accuracy_stringent<-read.csv("../data/reference/accuracy_stringent.csv",stringsAsFactors = F)
beta_Nb<-trans_fit(subset(trans_freq.comp,freq1<0.5)
                   ,l=seq(0.01,10,0.01),Nb_max=100,model="BetaBin",
                 threshold=0.02,acc=accuracy_stringent,
                 pair_id)
  
beta_Nb_sum<- beta_Nb %>% group_by(pair_id) %>% do(model_summary(.) )

beta_total_fit<-trans_fit(subset(trans_freq.comp,freq1<0.5)
                   ,l=seq(0.01,10,0.01),Nb_max=100,model="BetaBin",
                 threshold=0.02,acc=accuracy_stringent)

beta_fit_sum<-model_summary(beta_total_fit)
beta_fit_sum

write_to_summary("BB Nb:",beta_fit_sum$mean_Nb)
write_to_summary("BB lambda:",beta_fit_sum$lambda)
write_to_summary("BB CI:",paste(beta_fit_sum$lower_95,beta_fit_sum$upper_95,collapse = "-"))

```
### Loglikelihodd plot

```{r,eval=T}
beta_ll.p<-ggplot(beta_total_fit,aes(x=lambda_to_mean(lambda),y=LL))+geom_point()+ylab("Log Likelihood")+xlab("Average Bottleneck size")+scale_x_continuous(breaks=c(1:10))
beta_ll.p
require(cowplot)


```

### Fitting by person

```{r}
beta_Nb_sum<-beta_Nb_sum[order(beta_Nb_sum$mean_Nb,decreasing = T),]
beta_Nb_sum$y = 1:nrow(beta_Nb_sum)

ggplot()+geom_point(data=beta_Nb_sum,aes(y=y,x=lambda_to_mean(lower_95)),shape=108,size=4,color=cbPalette[2])+
  geom_point(data=beta_Nb_sum,aes(y=y,x=lambda_to_mean(upper_95)),shape=108,size=4,color=cbPalette[2])+
  geom_point(data=beta_Nb_sum,aes(y=y,x=mean_Nb),shape=108,size=5,color=cbPalette[5])+
  geom_segment(data=beta_Nb_sum,aes(x=lambda_to_mean(lower_95),xend=lambda_to_mean(upper_95),y=y,yend=y),color=cbPalette[2])+
  theme(axis.ticks.y =element_blank(),axis.line.y=element_blank())+
  scale_y_continuous(breaks=c())+ylab("Transmission pair")+xlab("Bottleneck")+
  scale_x_continuous(limits = c(0,10.1))

```

## Simulations


```{r,simulation_beta}
sim_trans_beta<-simulations(data=trans_freq.comp,runs = 1000,lambda = beta_fit_sum$lambda,
                          betabin_sim,threshold = 0.02,acc = accuracy_stringent,pair_id) # presence/absence # beta model
```

```{r}
beta_sim_plot<-sim_plot(trans_freq.comp,sim_trans_beta)
write.csv(rename(sim_trans_beta,frequency.in.donor=freq1,
                 probability.of.transmission=prob),"Figures/data/Figure3F.area.csv")
beta_sim_plot

```
## lambda = 10 
```{r,simulation_beta.10}
sim_trans_beta.10<-simulations(data=trans_freq.comp,runs = 10,lambda = 10,
                          betabin_sim,threshold = 0.02,acc = accuracy_stringent,pair_id) #
```

```{r}
beta_sim_plot.10<-sim_plot(trans_freq.comp,sim_trans_beta.10)
beta_sim_plot.10

```



```{r}
AIC<-function(df,k){
  2*k-2*max(df$LL)
}
kable(data.frame(Model= c("Presence/Absence","BetaBinomial"),AIC = c(AIC(pa_total_fit,1),AIC(beta_total_fit,1))))

write_to_summary("BB AIC:", AIC(beta_total_fit,1))
write_to_summary("P-A AIC:", AIC(pa_total_fit,1))

final_table<-data.frame(Model=c("Presence Absence","BetaBinomial"))
final_table<-cbind(final_table,rbind(pa_fit_sum,beta_fit_sum))

kable(final_table)


```

#Figure 3
```{r}
# load("./transmission_setup_plots.RData")
# require(cowplot)
# trans.com.plot<-trans.com.plot+xlab("Frequency in donor")
# fig_4=plot_grid(trans_freq.p, pa_sim_plot, trans.com.plot,beta_sim_plot, labels = c("A", "B", "C", "D"), ncol = 2,align = c("v","h"))#+draw_label("DRAFT!", angle = 45, size = 80, alpha = .2)
# 
# save_plot("./Figures/Figure_4.pdf", fig_4,
#           ncol = 2, # we're saving a grid plot of 2 columns
#           nrow = 2, # and 2 rows
#           # each individual subplot should have an aspect ratio of 1.3
#           base_aspect_ratio = 1.3
#           )
# embed_fonts("./Figures/Figure_4.pdf")
# fig_4



```

```{r}
save_plot("./Figures/Figure3D.pdf", pa_sim_plot,
          base_aspect_ratio = 1.3)
embed_fonts("./Figures/Figure3D.pdf")

save_plot("./Figures/Figure3F.pdf", beta_sim_plot,
          base_aspect_ratio = 1.3)
embed_fonts("./Figures/Figure3F.pdf")

save_plot("./Figures/Supplemental_Figure7D.pdf", no_cut_pa_sim_plot,
          base_aspect_ratio = 1.3)
embed_fonts("./Figures/Supplemental_Figure7D.pdf")

save_plot("./Figures/Supplemental_Figure7A.pdf", nc_ni_tv_plot,
          base_aspect_ratio = 1.3)
embed_fonts("./Figures/Supplemental_Figure7A.pdf")

save_plot("./Figures/Supplemental_Figure7B.pdf", nc_ni.pa_sim_plot,
          base_aspect_ratio = 1.3)
embed_fonts("./Figures/Supplemental_Figure7B.pdf")

```


